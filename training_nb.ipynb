{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import PromptLRN, VCPromptLRN, PromptOptim\n",
    "from dataset import Dataset\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_acc(pred, y, top_k=1):\n",
    "    if top_k == 1:\n",
    "        acc = (pred.reshape(-1,) == y).sum() / y.shape[0] * 100\n",
    "        return acc\n",
    "    else:\n",
    "        corr = 0\n",
    "        for p, t in zip(pred, y):\n",
    "            if t in p:\n",
    "                corr += 1\n",
    "        acc = corr / y.shape[0] * 100\n",
    "        return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2022)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EuroSAT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Training & Evaluation of 16 shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Text Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "proptim = PromptOptim(cfg=cfg, device=device, dataset='eurosat', kshot=16, type='text', start_epoch=0)\n",
    "proptim.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images evaluated\n",
      "54 images evaluated\n",
      "108 images evaluated\n",
      "162 images evaluated\n",
      "216 images evaluated\n",
      "270 images evaluated\n",
      "324 images evaluated\n",
      "378 images evaluated\n",
      "432 images evaluated\n",
      "486 images evaluated\n",
      "540 images evaluated\n",
      "594 images evaluated\n",
      "648 images evaluated\n",
      "702 images evaluated\n",
      "756 images evaluated\n",
      "810 images evaluated\n",
      "864 images evaluated\n",
      "918 images evaluated\n",
      "972 images evaluated\n",
      "1026 images evaluated\n",
      "1080 images evaluated\n",
      "1134 images evaluated\n",
      "1188 images evaluated\n",
      "1242 images evaluated\n",
      "1296 images evaluated\n",
      "1350 images evaluated\n",
      "1404 images evaluated\n",
      "1458 images evaluated\n",
      "1512 images evaluated\n",
      "1566 images evaluated\n",
      "1620 images evaluated\n",
      "1674 images evaluated\n",
      "1728 images evaluated\n",
      "1782 images evaluated\n",
      "1836 images evaluated\n",
      "1890 images evaluated\n",
      "1944 images evaluated\n",
      "1998 images evaluated\n",
      "2052 images evaluated\n",
      "2106 images evaluated\n",
      "2160 images evaluated\n",
      "2214 images evaluated\n",
      "2268 images evaluated\n",
      "2322 images evaluated\n",
      "2376 images evaluated\n",
      "2430 images evaluated\n",
      "2484 images evaluated\n",
      "2538 images evaluated\n",
      "2592 images evaluated\n",
      "2700 images evaluated\n",
      "2754 images evaluated\n",
      "2808 images evaluated\n",
      "2862 images evaluated\n",
      "top 1 Accuracy on eurosat dataset with 16 shot setting : 62.59259033203125%\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "############## config ##############\n",
    "device = torch.device('cpu')\n",
    "dataset = 'eurosat'\n",
    "epoch = 200\n",
    "type = 'text'\n",
    "kshot = 16\n",
    "topk = 1\n",
    "####################################\n",
    "\n",
    "# set model and evaluation dataloader \n",
    "testset = Dataset(dataset, kshot, train=False)\n",
    "testloader = DataLoader(testset, batch_size=100)\n",
    "if type == 'text':\n",
    "    model = PromptLRN(testset.labels, cfg, device)\n",
    "else:\n",
    "    model = VCPromptLRN(testset.labels, cfg, device)\n",
    "# load trained \n",
    "state_dict = torch.load('./ckpt/{}_promptlearn_{}/{}_shot/model_epoch{}.pt'.format(dataset, type, kshot, epoch))\n",
    "model.load_state_dict(state_dict())\n",
    "model.eval().to(device)\n",
    "ys = torch.tensor(testset.df.labels.values)\n",
    "preds = torch.tensor([])\n",
    "# evaluation iteration\n",
    "with torch.no_grad():\n",
    "    for step, pixel in enumerate(testloader):\n",
    "        logits = model(pixel.to(device))\n",
    "        pred = torch.topk(logits, k=topk, dim=1).indices\n",
    "        preds = torch.cat([preds, pred], dim=0)\n",
    "        if (step+1) % 50:\n",
    "            print('{} images evaluated'.format(step * len(testloader)))\n",
    "    acc = top_k_acc(preds, ys, top_k = topk)\n",
    "\n",
    "print('top {} Accuracy on {} dataset with {} shot setting : {}%'.format(topk, dataset, kshot, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Text Prompt + Visual Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "proptim = PromptOptim(cfg=cfg, device=device, dataset='eurosat', kshot=16, type='text+vision', start_epoch=0)\n",
    "proptim.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images evaluated\n",
      "54 images evaluated\n",
      "108 images evaluated\n",
      "162 images evaluated\n",
      "216 images evaluated\n",
      "270 images evaluated\n",
      "324 images evaluated\n",
      "378 images evaluated\n",
      "432 images evaluated\n",
      "486 images evaluated\n",
      "540 images evaluated\n",
      "594 images evaluated\n",
      "648 images evaluated\n",
      "702 images evaluated\n",
      "756 images evaluated\n",
      "810 images evaluated\n",
      "864 images evaluated\n",
      "918 images evaluated\n",
      "972 images evaluated\n",
      "1026 images evaluated\n",
      "1080 images evaluated\n",
      "1134 images evaluated\n",
      "1188 images evaluated\n",
      "1242 images evaluated\n",
      "1296 images evaluated\n",
      "1350 images evaluated\n",
      "1404 images evaluated\n",
      "1458 images evaluated\n",
      "1512 images evaluated\n",
      "1566 images evaluated\n",
      "1620 images evaluated\n",
      "1674 images evaluated\n",
      "1728 images evaluated\n",
      "1782 images evaluated\n",
      "1836 images evaluated\n",
      "1890 images evaluated\n",
      "1944 images evaluated\n",
      "1998 images evaluated\n",
      "2052 images evaluated\n",
      "2106 images evaluated\n",
      "2160 images evaluated\n",
      "2214 images evaluated\n",
      "2268 images evaluated\n",
      "2322 images evaluated\n",
      "2376 images evaluated\n",
      "2430 images evaluated\n",
      "2484 images evaluated\n",
      "2538 images evaluated\n",
      "2592 images evaluated\n",
      "2700 images evaluated\n",
      "2754 images evaluated\n",
      "2808 images evaluated\n",
      "2862 images evaluated\n",
      "top 1 Accuracy on eurosat dataset with 16 shot setting : 51.203704833984375%\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "############## config ##############\n",
    "device = torch.device('cpu')\n",
    "dataset = 'eurosat'\n",
    "epoch = 200\n",
    "type = 'text+vision'\n",
    "kshot = 16\n",
    "topk = 1\n",
    "####################################\n",
    "\n",
    "# set model and evaluation dataloader \n",
    "testset = Dataset(dataset, kshot, train=False)\n",
    "testloader = DataLoader(testset, batch_size=100)\n",
    "if type == 'text':\n",
    "    model = PromptLRN(testset.labels, cfg, device)\n",
    "else:\n",
    "    model = VCPromptLRN(testset.labels, cfg, device)\n",
    "# load trained \n",
    "state_dict = torch.load('./ckpt/{}_promptlearn_{}/{}_shot/model_epoch{}.pt'.format(dataset, type, kshot, epoch))\n",
    "model.load_state_dict(state_dict())\n",
    "model.eval().to(device)\n",
    "ys = torch.tensor(testset.df.labels.values)\n",
    "preds = torch.tensor([])\n",
    "# evaluation iteration\n",
    "with torch.no_grad():\n",
    "    for step, pixel in enumerate(testloader):\n",
    "        logits = model(pixel.to(device))\n",
    "        pred = torch.topk(logits, k=topk, dim=1).indices\n",
    "        preds = torch.cat([preds, pred], dim=0)\n",
    "        if (step+1) % 50:\n",
    "            print('{} images evaluated'.format(step * len(testloader)))\n",
    "    acc = top_k_acc(preds, ys, top_k = topk)\n",
    "\n",
    "print('top {} Accuracy on {} dataset with {} shot setting : {}%'.format(topk, dataset, kshot, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Training & Evaluation of 8-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Text Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "proptim = PromptOptim(cfg=cfg, device=device, dataset='eurosat', kshot=8, type='text', start_epoch=0)\n",
    "proptim.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images evaluated\n",
      "54 images evaluated\n",
      "108 images evaluated\n",
      "162 images evaluated\n",
      "216 images evaluated\n",
      "270 images evaluated\n",
      "324 images evaluated\n",
      "378 images evaluated\n",
      "432 images evaluated\n",
      "486 images evaluated\n",
      "540 images evaluated\n",
      "594 images evaluated\n",
      "648 images evaluated\n",
      "702 images evaluated\n",
      "756 images evaluated\n",
      "810 images evaluated\n",
      "864 images evaluated\n",
      "918 images evaluated\n",
      "972 images evaluated\n",
      "1026 images evaluated\n",
      "1080 images evaluated\n",
      "1134 images evaluated\n",
      "1188 images evaluated\n",
      "1242 images evaluated\n",
      "1296 images evaluated\n",
      "1350 images evaluated\n",
      "1404 images evaluated\n",
      "1458 images evaluated\n",
      "1512 images evaluated\n",
      "1566 images evaluated\n",
      "1620 images evaluated\n",
      "1674 images evaluated\n",
      "1728 images evaluated\n",
      "1782 images evaluated\n",
      "1836 images evaluated\n",
      "1890 images evaluated\n",
      "1944 images evaluated\n",
      "1998 images evaluated\n",
      "2052 images evaluated\n",
      "2106 images evaluated\n",
      "2160 images evaluated\n",
      "2214 images evaluated\n",
      "2268 images evaluated\n",
      "2322 images evaluated\n",
      "2376 images evaluated\n",
      "2430 images evaluated\n",
      "2484 images evaluated\n",
      "2538 images evaluated\n",
      "2592 images evaluated\n",
      "2700 images evaluated\n",
      "2754 images evaluated\n",
      "2808 images evaluated\n",
      "2862 images evaluated\n",
      "top 1 Accuracy on eurosat dataset with 8 shot setting : 48.55555725097656%\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "############## config ##############\n",
    "device = torch.device('cpu')\n",
    "dataset = 'eurosat'\n",
    "epoch = 100\n",
    "type = 'text'\n",
    "kshot = 8\n",
    "topk = 1\n",
    "####################################\n",
    "\n",
    "# set model and evaluation dataloader \n",
    "testset = Dataset(dataset, kshot, train=False)\n",
    "testloader = DataLoader(testset, batch_size=100)\n",
    "if type == 'text':\n",
    "    model = PromptLRN(testset.labels, cfg, device)\n",
    "else:\n",
    "    model = VCPromptLRN(testset.labels, cfg, device)\n",
    "# load trained \n",
    "state_dict = torch.load('./ckpt/{}_promptlearn_{}/{}_shot/model_epoch{}.pt'.format(dataset, type, kshot, epoch))\n",
    "model.load_state_dict(state_dict())\n",
    "model.eval().to(device)\n",
    "ys = torch.tensor(testset.df.labels.values)\n",
    "preds = torch.tensor([])\n",
    "# evaluation iteration\n",
    "with torch.no_grad():\n",
    "    for step, pixel in enumerate(testloader):\n",
    "        logits = model(pixel.to(device))\n",
    "        pred = torch.topk(logits, k=topk, dim=1).indices\n",
    "        preds = torch.cat([preds, pred], dim=0)\n",
    "        if (step+1) % 50:\n",
    "            print('{} images evaluated'.format(step * len(testloader)))\n",
    "    acc = top_k_acc(preds, ys, top_k = topk)\n",
    "\n",
    "print('top {} Accuracy on {} dataset with {} shot setting : {}%'.format(topk, dataset, kshot, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Text Prompt + Visual Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proptim = PromptOptim(cfg=cfg, device=device, dataset='eurosat', kshot=8, type='text+vision', start_epoch=0)\n",
    "proptim.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images evaluated\n",
      "54 images evaluated\n",
      "108 images evaluated\n",
      "162 images evaluated\n",
      "216 images evaluated\n",
      "270 images evaluated\n",
      "324 images evaluated\n",
      "378 images evaluated\n",
      "432 images evaluated\n",
      "486 images evaluated\n",
      "540 images evaluated\n",
      "594 images evaluated\n",
      "648 images evaluated\n",
      "702 images evaluated\n",
      "756 images evaluated\n",
      "810 images evaluated\n",
      "864 images evaluated\n",
      "918 images evaluated\n",
      "972 images evaluated\n",
      "1026 images evaluated\n",
      "1080 images evaluated\n",
      "1134 images evaluated\n",
      "1188 images evaluated\n",
      "1242 images evaluated\n",
      "1296 images evaluated\n",
      "1350 images evaluated\n",
      "1404 images evaluated\n",
      "1458 images evaluated\n",
      "1512 images evaluated\n",
      "1566 images evaluated\n",
      "1620 images evaluated\n",
      "1674 images evaluated\n",
      "1728 images evaluated\n",
      "1782 images evaluated\n",
      "1836 images evaluated\n",
      "1890 images evaluated\n",
      "1944 images evaluated\n",
      "1998 images evaluated\n",
      "2052 images evaluated\n",
      "2106 images evaluated\n",
      "2160 images evaluated\n",
      "2214 images evaluated\n",
      "2268 images evaluated\n",
      "2322 images evaluated\n",
      "2376 images evaluated\n",
      "2430 images evaluated\n",
      "2484 images evaluated\n",
      "2538 images evaluated\n",
      "2592 images evaluated\n",
      "2700 images evaluated\n",
      "2754 images evaluated\n",
      "2808 images evaluated\n",
      "2862 images evaluated\n",
      "top 1 Accuracy on eurosat dataset with 8 shot setting : 46.296295166015625%\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "############## config ##############\n",
    "device = torch.device('cpu')\n",
    "dataset = 'eurosat'\n",
    "epoch = 100\n",
    "type = 'text+vision'\n",
    "kshot = 8\n",
    "topk = 1\n",
    "####################################\n",
    "\n",
    "# set model and evaluation dataloader \n",
    "testset = Dataset(dataset, kshot, train=False)\n",
    "testloader = DataLoader(testset, batch_size=100)\n",
    "if type == 'text':\n",
    "    model = PromptLRN(testset.labels, cfg, device)\n",
    "else:\n",
    "    model = VCPromptLRN(testset.labels, cfg, device)\n",
    "# load trained \n",
    "state_dict = torch.load('./ckpt/{}_promptlearn_{}/{}_shot/model_epoch{}.pt'.format(dataset, type, kshot, epoch))\n",
    "model.load_state_dict(state_dict())\n",
    "model.eval().to(device)\n",
    "ys = torch.tensor(testset.df.labels.values)\n",
    "preds = torch.tensor([])\n",
    "# evaluation iteration\n",
    "with torch.no_grad():\n",
    "    for step, pixel in enumerate(testloader):\n",
    "        logits = model(pixel.to(device))\n",
    "        pred = torch.topk(logits, k=topk, dim=1).indices\n",
    "        preds = torch.cat([preds, pred], dim=0)\n",
    "        if (step+1) % 50:\n",
    "            print('{} images evaluated'.format(step * len(testloader)))\n",
    "    acc = top_k_acc(preds, ys, top_k = topk)\n",
    "\n",
    "print('top {} Accuracy on {} dataset with {} shot setting : {}%'.format(topk, dataset, kshot, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = edict()\n",
    "\n",
    "# dataset\n",
    "result.eurosat = edict()\n",
    "result.fgvcaircraft = edict()\n",
    "\n",
    "# k_shot\n",
    "result.eurosat.shot8 = edict()\n",
    "result.eurosat.shot16 = edict()\n",
    "\n",
    "# bakcbone\n",
    "result.eurosat.shot8.clip_vit_b32 = edict()\n",
    "result.eurosat.shot16.clip_vit_b32 = edict()\n",
    "\n",
    "# approach\n",
    "result.eurosat.shot8.clip_vit_b32.text_prompt = edict()\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt = edict()\n",
    "\n",
    "# hyperparams & accuracy\n",
    "## 16 shot\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1 = edict()\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1.hyperparams = {'epochs':200, 'ctx_len':16}\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1.acc = 62.59\n",
    "\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1 = edict()\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1.hyperparams = {'epochs':200, 'ctx_len':16, 'v_ctx_len':5}\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1.acc = 51.2\n",
    "\n",
    "## 8 shot\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1 = edict()\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1.hyperparams = {'epochs':200, 'ctx_len':16}\n",
    "result.eurosat.shot16.clip_vit_b32.text_prompt.v1.acc = 62.59\n",
    "\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1 = edict()\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1.hyperparams = {'epochs':200, 'ctx_len':16, 'v_ctx_len':5}\n",
    "result.eurosat.shot16.clip_vit_b32.visual_text_prompt.v1.acc = 51.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'ctx_len': 16, 'v_ctx_len': 5, 't_h_dim': 512, 'v_h_dim': 768},\n",
       " 'train': {'n_epochs': 100,\n",
       "  'batch_size': 32,\n",
       "  'k_shot': 16,\n",
       "  'base_lr': 1e-05,\n",
       "  'max_lr': 0.002,\n",
       "  'pct_start': 0.01},\n",
       " 'eval': {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.eurosat.shot8.clip_vit_b32.text_prompt.hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a06f093cbaeec228923b48b78a81a3ad5fd7f429a83b09002ee2923fc0db60a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('imagegpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
